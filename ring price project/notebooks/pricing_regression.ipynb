{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = os.path.join('..', 'data', 'raw', 'ring_details.xlsx')\n",
    "df0 = pd.read_excel(raw_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df0.drop(columns = ['Image', 'Reference', 'Series:', 'Model:','Model Variant:','Category:', 'Style Type:','Range:','Stone Type:','Stone Description:','Diamond Round / Brilliant Cut - Various mm:','£ Per g'])\n",
    "df0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0[df0['Setting Style:'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df0.dropna(subset=['Setting Style:', 'Price']).reset_index(drop=True)\n",
    "df0.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Extraction\n",
    "df0['Guide Weight:'] = df0['Guide Weight:'].str.extract(r'(\\d+\\.?\\d*)').astype(float)\n",
    "df0['Stone Size (ct):'] = df0['Stone Size (ct):'].str.extract(r'(\\d+\\.?\\d*)').astype(float)\n",
    "df0['Stone Size (mm):'] = df0['Stone Size (mm):'].replace({' mm': '', 'mm':''}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorganize_stone_size(row):\n",
    "    stone_shape = row['Stone Shape:']\n",
    "    stone_size = row['Stone Size (mm):']\n",
    "    \n",
    "    if stone_shape in ['Cushion Cut', 'Princess / Square Cut', 'Asscher Cut']:\n",
    "        # Single number, interpreted as width (or length)\n",
    "        return {'Width': float(stone_size), 'Length': float(stone_size)}\n",
    "    elif stone_shape == 'Round / Brilliant Cut':\n",
    "        # Single number, interpreted as diameter\n",
    "        return {'Diameter': float(stone_size)}\n",
    "    else:\n",
    "        # For other shapes, split 'length x width' into two numbers\n",
    "        if 'x' in stone_size:\n",
    "            length, width = map(float, stone_size.split('x'))\n",
    "            return {'Length': length, 'Width': width}\n",
    "        else:\n",
    "            # Handle cases where the format is unexpected\n",
    "            return {'Length': None, 'Width': None}\n",
    "\n",
    "# Apply the function to reorganize the 'Stone Size' column\n",
    "stone_size_data = df.apply(reorganize_stone_size, axis=1)\n",
    "\n",
    "# Convert the resulting dictionary into separate columns\n",
    "stone_size_df = pd.DataFrame(stone_size_data.tolist())\n",
    "\n",
    "# Merge the new columns back into the original DataFrame\n",
    "df = pd.concat([df, stone_size_df], axis=1)\n",
    "\n",
    "df.drop(columns=['Stone Size (mm):'], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_path = os.path.join('..', 'data', 'processed', 'cleaned_ring_data.csv')\n",
    "df.to_csv(processed_path, index=False)\n",
    "print(f\"Cleaned data saved to: {processed_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning & EDA \n",
    "\n",
    "# 1. Fill missing values\n",
    "df['Stone Size (ct)'] = df['Stone Size (ct):'].fillna(0)\n",
    "\n",
    "\n",
    "# 2. Explanatory Data Analysis EDA (展示專業性)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df['Price'], kde=True)\n",
    "plt.title('Price Distribution')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.scatterplot(data=df, x='Stone Size (ct)', y='Price', hue='Alloy:', alpha=0.5)\n",
    "plt.title('Stone Size vs Price')\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.scatterplot(data=df, x='Stone Size (ct)', y='Price', hue='Alloy:', alpha=0.6)\n",
    "plt.title('Relationship between Stone Carat and Price')\n",
    "plt.show()\n",
    "\n",
    "print(\"Data cleaning completed and EDA visualization generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Diameter', 'Length', 'Width']] = df[['Diameter', 'Length', 'Width']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = df[(df['Diameter'].isna()) & (df['Length'].isna()) & (df['Width'].isna())]\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = df.select_dtypes(include=['object']).columns\n",
    "df = pd.get_dummies(df, columns=obj_cols, drop_first=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Price'])\n",
    "y = df['Price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 4)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size = 0.3, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_tr), len(X_val), len(y_tr), len(y_val), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'RandomForest': RandomForestRegressor(),\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(),\n",
    "    'SVR': SVR()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale X_tr, X_val, and X_test separately\n",
    "scaler = StandardScaler()\n",
    "X_tr_scaled = scaler.fit_transform(X_tr)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_tr = np.log(y_tr)\n",
    "y_val = np.log(y_val)\n",
    "y_test = np.log(y_test)\n",
    "\n",
    "# Define a pipeline without the scaler\n",
    "pipeline = Pipeline([\n",
    "    ('model', None)  # Placeholder for the model\n",
    "])\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = [\n",
    "    {'model': [models['RandomForest']], 'model__n_estimators': [50, 100, 200]},\n",
    "    {'model': [models['LinearRegression']]},\n",
    "    {'model': [models['Ridge']], 'model__alpha': [0.1, 1.0, 10.0]},\n",
    "    {'model': [models['Lasso']], 'model__alpha': [0.1, 1.0, 10.0]},\n",
    "    {'model': [models['SVR']], 'model__C': [0.1, 1.0, 10.0], 'model__kernel': ['linear', 'rbf']}\n",
    "]\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Handle NaN values in X_tr_scaled, X_val_scaled, and X_test_scaled\n",
    "X_tr_scaled = np.nan_to_num(X_tr_scaled, nan=0.0)\n",
    "X_val_scaled = np.nan_to_num(X_val_scaled, nan=0.0)\n",
    "X_test_scaled = np.nan_to_num(X_test_scaled, nan=0.0)\n",
    "\n",
    "grid_search.fit(X_tr_scaled, y_tr)\n",
    "\n",
    "# Display the best model and its parameters\n",
    "print(\"Best Model:\", grid_search.best_estimator_)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\", font_scale=0.8)\n",
    "\n",
    "# Extract the best model from grid search\n",
    "best_model = grid_search.best_estimator_.named_steps['model']\n",
    "\n",
    "# Check if the best model has coefficients (beta values)\n",
    "if hasattr(best_model, 'coef_'):\n",
    "    # Get the feature names\n",
    "    feature_names = X.columns\n",
    "    # Get the beta coefficients\n",
    "    betas = best_model.coef_\n",
    "    \n",
    "    # Create a DataFrame for better visualization\n",
    "    beta_df = pd.DataFrame({'Feature': feature_names, 'Beta': betas})\n",
    "    beta_df = beta_df.sort_values(by='Beta', ascending=False)\n",
    "\n",
    "    # Display the beta coefficients\n",
    "    print(beta_df)\n",
    "\n",
    "    # Plot the beta coefficients\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Beta', y='Feature', data=beta_df)\n",
    "    plt.title('Feature Importances (Beta Coefficients)')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"The best model does not have beta coefficients.\")\n",
    "\n",
    "# For tree-based models like RandomForest, plot feature importances\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    # Get the feature importances\n",
    "    importances = best_model.feature_importances_\n",
    "    \n",
    "    # Create a DataFrame for better visualization\n",
    "    importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Display the feature importances\n",
    "    importance_df\n",
    "\n",
    "    # Plot the feature importances\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
    "    plt.title('Feature Importances')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"The best model does not have feature importances.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "linear_model.fit(X_tr_scaled, y_tr)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = linear_model.predict(X_val_scaled)\n",
    "\n",
    "# Calculate the mean squared error and R2 score\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted values for the linear regression model\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_val, y_val_pred, alpha=0.6, color='blue', label='Predicted vs Actual')\n",
    "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'k--', lw=2, color='red', label='Ideal Fit')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Linear Regression: Actual vs Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature names from X\n",
    "feature_names = X.columns\n",
    "\n",
    "# Extract beta coefficients from the linear regression model\n",
    "betas = linear_model.coef_\n",
    "\n",
    "# Create a DataFrame for the beta coefficients of the linear regression model\n",
    "beta_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Beta': betas\n",
    "})\n",
    "\n",
    "# Disable scientific formatting for better readability\n",
    "pd.options.display.float_format = '{:.6f}'.format\n",
    "\n",
    "# Display the beta coefficients\n",
    "beta_df = beta_df.sort_values(by='Beta', ascending=False)\n",
    "beta_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust font size for better readability\n",
    "sns.set_context(\"talk\", font_scale=0.8)\n",
    "\n",
    "# Plot the beta coefficients\n",
    "plt.figure(figsize=(10, 12))  # Increase figure height for better spacing\n",
    "sns.barplot(x='Beta', y='Feature', data=beta_df)\n",
    "plt.title('Linear Regression: Feature Importances (Beta Coefficients)')\n",
    "plt.xlabel('Beta Coefficient')\n",
    "plt.ylabel('Feature')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()  # Adjust layout to prevent overlapping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df.sort_values(by='Importance', ascending=False).head(20))\n",
    "plt.title('Top 20 Feature Importances')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Predictions for RandomForestRegressor on the validation set\n",
    "y_val_pred_rf = best_model.predict(X_val_scaled)\n",
    "\n",
    "# Calculate RMSE and R² for RandomForestRegressor\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_val, y_val_pred_rf))\n",
    "r2_rf = r2_score(y_val, y_val_pred_rf)\n",
    "\n",
    "# Calculate RMSE and R² for LinearRegression (recompute if necessary)\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_val, y_val_pred))  # Recompute RMSE for LinearRegression\n",
    "r2_lr = r2  # r2 is already defined for LinearRegression\n",
    "\n",
    "# Differences\n",
    "rmse_diff = rmse_lr - rmse_rf\n",
    "r2_diff = r2_lr - r2_rf\n",
    "\n",
    "print(f\"RMSE Difference (LinearRegression - RandomForest): {rmse_diff}\")\n",
    "print(f\"R² Difference (LinearRegression - RandomForest): {r2_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `feature_names` contains the names of the features and `betas` contains the coefficients\n",
    "intercept = linear_model.intercept_  # Intercept of the model\n",
    "formula = f\"Logistic Regression Formula: logit(P) = {intercept:.4f}\"\n",
    "\n",
    "for feature, beta in zip(feature_names, betas):\n",
    "    formula += f\" + ({beta:.4f} * {feature})\"\n",
    "\n",
    "print(formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the beta coefficients\n",
    "beta_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Beta': betas\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by the absolute value of the beta coefficients for better visualization\n",
    "beta_df = beta_df.reindex(beta_df['Beta'].sort_values(ascending=False).index)\n",
    "\n",
    "# Display the DataFrame\n",
    "beta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on the test set\n",
    "y_test_pred = linear_model.predict(X_test_scaled)\n",
    "# Calculate RMSE and R² for the test set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "# Calculate the differences\n",
    "rmse_diff = rmse_lr - rmse_test\n",
    "r2_diff = r2_lr - r2_test\n",
    "\n",
    "# Create a DataFrame to display the R2 and RMSE metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['Validation', 'Test', 'Difference'],\n",
    "    'R2': [r2, r2_test, r2_diff],\n",
    "    'RMSE': [rmse, rmse_test, rmse_diff]\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "metrics_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
